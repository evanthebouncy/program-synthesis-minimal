---
layout: post
title:  "fine-tuned llm as program writers"
permalink: /generation-with-llm/
---

A program-writer is a conduit between specifications and programs. In this post, we will explain how large language models (llm) can be an universal program-writer for different domains.

## a menagerie of synthesizers

The synthesizer has a difficult job. It takes in semantics -- what the program should _do_, and produces syntax -- how the program should _look_. Synthesis is running an interpreter backwards.

![Image with caption](/program-synthesis-primer/assets/llm-generation/dual.png){: width="75%" }

Given this hard problem, it seems reasonable that for every problem domain there needs to be a domain-specific synthesizer tailored to it. This has indeed been the case. Here's a collection of program-writer architectures in some of my works.

![Image with caption](/program-synthesis-primer/assets/llm-generation/zoo.png){: width="95%" }

While they look cool, significant engineering efforts were required to ensure that:
1. the tasks from a domain can be concisely expressed in the programming DSL
2. the synthesizer can reliably interpret the specification in its given form
3. the synthesizer can reliably generate legal programs in the DSL
4. the synthesizer can actually learn the structure of the meaning matrix M through training

This results in a messy co-evolution of DSL, interpreter, specification, and synthesizer -- as the program-writer architecture is highly coupled with the specification language and the DSL.

# large language models

A **large language model** (llm) transforms an input text string to an output text string. Trained on an enormous amount of textual data, it can make some pretty surprising transformations.

![openai codex](/program-synthesis-primer/assets/llm-generation/codex.png){: width="95%" }

The capabilities and limitations of llm are (as of 2022-aug) still being investigated. As I am learning about it myself, I encourage you to become familiar with them elsewhere. 

## llm for synthesis ?
These are my own assessments on why llm are useful for program synthesis. To make my case, I will show some interactions through prompting with the openai-codex model.

### llm can pick-up programmatic patterns
Programs are stylized, patterned texts with distinct rules governing its generation and interpretation. It seems llm are predisposed to pick up these programmatic patterns.

![openai codex](/program-synthesis-primer/assets/llm-generation/codex-prog.png){: width="70%" }

### llm has conventional knowledge of human language
Trained on human written text, llm has a basic understanding of human conventions.

![openai codex](/program-synthesis-primer/assets/llm-generation/codex-convention.png){: width="95%" }

### llm are reliable in generating syntactically complex programs
Practitioners of program synthesis have avoided free-form text generation, as they're rarely coherent. However, llm are very good at generating stylistically consistent texts.

![openai codex](/program-synthesis-primer/assets/llm-generation/codex-coherent1.png){: width="60%" }

### llm operates over text -- a universal datatype
The specifications and programs are often easily represented as structured texts, this allow you to easily integrate program synthesis with an existing programming system, or iterate through different DSLs and specification languages -- no parser required.

![openai codex](/program-synthesis-primer/assets/llm-generation/codex-reframe.png){: width="80%" }

## where prompting falls short
However, for more complex tasks, prompting alone will not work. For our rectangle example, prompting cannot be used to generate a valid rectangle for the spec.

![openai codex](/program-synthesis-primer/assets/llm-generation/prompt-fail1.png){: width="100%" }

For these more complex tasks, we turn to fine-tuning.

<br>
<hr>
[Let's take a break](https://youtu.be/BHfKutz21do) and stretch.
<hr>
<br>

# fine-tuning large language models for synthesis

When one **fine-tune** a model, they take an existing model with reasonable weights, and _continue to train it_ on a specific dataset. In program synthesis, we take an existing llm (i.e. codex), and fine-tune it on the dataset D generated by sampling the meaning matrix M.

